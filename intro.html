<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Introduction & Objectives</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />

  <style>
    body, h2, h4, p, li {
      color: white !important;
    }

    ul li::marker {
      color: white;
    }

    .text-primary,
    .text-success {
      color: white !important;
    }

    .card.border-primary,
    .card.border-success {
      border-color: white !important;
    }

    body {
      background-color: transparent;
      padding: 20px;
    }

    .card {
      background-color: transparent;
      border-radius: 10px;
      box-shadow: 0 0 8px rgba(255, 255, 255, 0.2);
    }
  </style>
</head>
<body>

  <main class="container py-4">

    <div class="mb-5">
      <h2 class="fw-bold">Introduction & Objectives</h2>
    </div>

    <div class="card border-primary mb-4 shadow-sm">
      <div class="card-body">
        <h4 class="card-title text-primary">Project Motivation</h4>
        <p class="card-text">
          In today's entertainment ecosystem, where recommendation systems drive what users watch next, accurate genre classification plays a critical role.
          Traditionally, genre prediction models have relied on either textual metadata like plot summaries or visual elements such as posters. However, each modality has its limitations when used in isolation.
        </p>
        <p class="card-text">
          Plot summaries may capture storyline details but miss stylistic or emotional cues that visuals provide. Posters, on the other hand, communicate mood and genre visually but lack narrative depth.
          This project explores how combining both — text and image — can create a more robust and context-aware genre classifier.
        </p>
      </div>
    </div>

    <div class="card border-success shadow-sm">
      <div class="card-body">
        <h4 class="card-title text-success">Project Goals</h4>
        <p class="card-text">
          Our primary objective is to build a multi-modal deep learning model that predicts one or more genres of a movie based on its plot summary and poster image.
          Through this project, we aim to:
        </p>
        <ul>
          <li>Demonstrate how fusion of text and image data improves classification accuracy</li>
          <li>Compare multi-modal performance against single-modality baselines</li>
          <li>Provide a reproducible implementation using state-of-the-art deep learning models</li>
          <li>Highlight challenges and opportunities in multi-modal classification tasks</li>
        </ul>
      </div>
    </div>

  </main>

</body>
</html>
